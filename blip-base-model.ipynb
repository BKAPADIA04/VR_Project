{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11657781,"sourceType":"datasetVersion","datasetId":7315783},{"sourceId":11663595,"sourceType":"datasetVersion","datasetId":7319871},{"sourceId":11780463,"sourceType":"datasetVersion","datasetId":7396008},{"sourceId":11813676,"sourceType":"datasetVersion","datasetId":7420042},{"sourceId":11818079,"sourceType":"datasetVersion","datasetId":7423091}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_df = pd.read_csv('/kaggle/input/finale-dataset/train_dataset.csv')\ntest_df = pd.read_csv('/kaggle/input/finale-dataset/test_dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:57:26.333872Z","iopub.execute_input":"2025-05-18T07:57:26.334093Z","iopub.status.idle":"2025-05-18T07:57:26.451688Z","shell.execute_reply.started":"2025-05-18T07:57:26.334076Z","shell.execute_reply":"2025-05-18T07:57:26.450779Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# final_df= final_df.head(38000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:57:28.342321Z","iopub.execute_input":"2025-05-18T07:57:28.342596Z","iopub.status.idle":"2025-05-18T07:57:28.346728Z","shell.execute_reply.started":"2025-05-18T07:57:28.342577Z","shell.execute_reply":"2025-05-18T07:57:28.345754Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"final_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:57:28.719715Z","iopub.execute_input":"2025-05-18T07:57:28.720014Z","iopub.status.idle":"2025-05-18T07:57:28.730889Z","shell.execute_reply.started":"2025-05-18T07:57:28.719991Z","shell.execute_reply":"2025-05-18T07:57:28.729945Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"      image_id                              question        answer  \\\n0  71BN3iMoGkL    What are the figurines sitting on?         Bench   \n1  71AH7yyOgCL  What brand is the mobile phone case?        Solimo   \n2  71ag2dwtVfL                   What brand is this?  AmazonBasics   \n3  61yqMXIGHVL  What lining do these envelopes have?        Bubble   \n4  71d57C76BpL              What is the shade shape?          Drum   \n\n              path  \n0  9d/9dd2d3f1.jpg  \n1  f3/f3ab1fbf.jpg  \n2  62/62075c07.jpg  \n3  2d/2d483c93.jpg  \n4  b8/b8b510a2.jpg  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>71BN3iMoGkL</td>\n      <td>What are the figurines sitting on?</td>\n      <td>Bench</td>\n      <td>9d/9dd2d3f1.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>71AH7yyOgCL</td>\n      <td>What brand is the mobile phone case?</td>\n      <td>Solimo</td>\n      <td>f3/f3ab1fbf.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71ag2dwtVfL</td>\n      <td>What brand is this?</td>\n      <td>AmazonBasics</td>\n      <td>62/62075c07.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61yqMXIGHVL</td>\n      <td>What lining do these envelopes have?</td>\n      <td>Bubble</td>\n      <td>2d/2d483c93.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71d57C76BpL</td>\n      <td>What is the shade shape?</td>\n      <td>Drum</td>\n      <td>b8/b8b510a2.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"len(final_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:57:31.154438Z","iopub.execute_input":"2025-05-18T07:57:31.154740Z","iopub.status.idle":"2025-05-18T07:57:31.159865Z","shell.execute_reply.started":"2025-05-18T07:57:31.154719Z","shell.execute_reply":"2025-05-18T07:57:31.159172Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"63639"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"len(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:57:31.406532Z","iopub.execute_input":"2025-05-18T07:57:31.406816Z","iopub.status.idle":"2025-05-18T07:57:31.411907Z","shell.execute_reply.started":"2025-05-18T07:57:31.406793Z","shell.execute_reply":"2025-05-18T07:57:31.411259Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"15910"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"## BASE MODEL","metadata":{}},{"cell_type":"code","source":"!pip install -q peft accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:57:43.581059Z","iopub.execute_input":"2025-05-18T07:57:43.581423Z","iopub.status.idle":"2025-05-18T07:57:47.264742Z","shell.execute_reply.started":"2025-05-18T07:57:43.581401Z","shell.execute_reply":"2025-05-18T07:57:47.263652Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"!pip install transformers torch torchvision pillow\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:58:14.896131Z","iopub.execute_input":"2025-05-18T07:58:14.896878Z","iopub.status.idle":"2025-05-18T07:58:18.538902Z","shell.execute_reply.started":"2025-05-18T07:58:14.896847Z","shell.execute_reply":"2025-05-18T07:58:18.537971Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\nfrom PIL import Image\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom bert_score import score\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Model & processor\nmodel_name = \"Salesforce/blip-vqa-base\"\nprocessor = BlipProcessor.from_pretrained(model_name)\nmodel = BlipForQuestionAnswering.from_pretrained(model_name).to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:58:44.129047Z","iopub.execute_input":"2025-05-18T07:58:44.129372Z","iopub.status.idle":"2025-05-18T07:58:46.095625Z","shell.execute_reply.started":"2025-05-18T07:58:44.129345Z","shell.execute_reply":"2025-05-18T07:58:46.094673Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"BlipForQuestionAnswering(\n  (vision_model): BlipVisionModel(\n    (embeddings): BlipVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (encoder): BlipEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x BlipEncoderLayer(\n          (self_attn): BlipAttention(\n            (dropout): Dropout(p=0.0, inplace=False)\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (projection): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): BlipMLP(\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (text_encoder): BlipTextModel(\n    (embeddings): BlipTextEmbeddings(\n      (word_embeddings): Embedding(30524, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): BlipTextEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BlipTextLayer(\n          (attention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (crossattention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): BlipTextIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BlipTextOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (text_decoder): BlipTextLMHeadModel(\n    (bert): BlipTextModel(\n      (embeddings): BlipTextEmbeddings(\n        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (encoder): BlipTextEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BlipTextLayer(\n            (attention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (crossattention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (intermediate): BlipTextIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BlipTextOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (cls): BlipTextOnlyMLMHead(\n      (predictions): BlipTextLMPredictionHead(\n        (transform): BlipTextPredictionHeadTransform(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (transform_act_fn): GELUActivation()\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(self, df, image_dir, processor):\n        self.df = df.reset_index(drop=True)\n        self.image_dir = image_dir\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.image_dir, row[\"path\"])\n        image = Image.open(img_path).convert(\"RGB\")\n        question = row[\"question\"]\n\n        inputs = self.processor(\n            image,\n            question,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            max_length=128,\n            truncation=True\n        )\n        return {\n            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n            \"answer\": row[\"answer\"]\n        }\n\ndef collate_fn(batch):\n    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n    answers = [item[\"answer\"] for item in batch]\n    return {\n        \"pixel_values\": pixel_values,\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"answer\": answers\n    }\n\n\n\nimage_dir = \"/kaggle/input/vr-dataset/small/small\" \n\ntest_dataset = VQADataset(test_df, image_dir, processor)\ntest_loader = DataLoader(test_dataset, batch_size=8, collate_fn=collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:59:11.821604Z","iopub.execute_input":"2025-05-18T07:59:11.822300Z","iopub.status.idle":"2025-05-18T07:59:11.834203Z","shell.execute_reply.started":"2025-05-18T07:59:11.822270Z","shell.execute_reply":"2025-05-18T07:59:11.833345Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"predictions = []\ntrue_answers = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        pixel_values = batch[\"pixel_values\"].to(device)\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n\n        outputs = model.generate(\n            pixel_values=pixel_values,\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            max_new_tokens=10,\n            use_cache=True\n        )\n\n        preds = processor.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        predictions.extend(preds)\n        true_answers.extend(batch[\"answer\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:59:28.311723Z","iopub.execute_input":"2025-05-18T07:59:28.312035Z","iopub.status.idle":"2025-05-18T08:11:57.087917Z","shell.execute_reply.started":"2025-05-18T07:59:28.312013Z","shell.execute_reply":"2025-05-18T08:11:57.087028Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"test_df[\"predicted_answer\"] = predictions\ntest_df[\"Answer_clean\"] = test_df[\"answer\"].astype(str).str.lower().str.strip()\ntest_df[\"Pred_clean\"] = test_df[\"predicted_answer\"].astype(str).str.lower().str.strip()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:14:08.806564Z","iopub.execute_input":"2025-05-18T08:14:08.807419Z","iopub.status.idle":"2025-05-18T08:14:08.831545Z","shell.execute_reply.started":"2025-05-18T08:14:08.807391Z","shell.execute_reply":"2025-05-18T08:14:08.830587Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:14:33.624689Z","iopub.execute_input":"2025-05-18T08:14:33.624965Z","iopub.status.idle":"2025-05-18T08:14:33.636422Z","shell.execute_reply.started":"2025-05-18T08:14:33.624944Z","shell.execute_reply":"2025-05-18T08:14:33.635683Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"      image_id                             question    answer  \\\n0  71OQ4BiD3uL            What is the product type?    Bucket   \n1  81CtH3N+0NL   What kind of closure does it have?   Lace-up   \n2  8176aHTRP3L           What is the primary color?     Multi   \n3  71yC+5KLN-L  What material is the cover made of?      Hard   \n4  71pP-5SEtyL   What material is the case made of?  Silicone   \n\n              path predicted_answer Answer_clean Pred_clean  \n0  f0/f0d50e0a.jpg               no       bucket         no  \n1  52/521668c5.jpg          sliding      lace-up    sliding  \n2  43/438d87ff.jpg             blue        multi       blue  \n3  30/304914ac.jpg            metal         hard      metal  \n4  40/40d177f8.jpg            metal     silicone      metal  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>path</th>\n      <th>predicted_answer</th>\n      <th>Answer_clean</th>\n      <th>Pred_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>71OQ4BiD3uL</td>\n      <td>What is the product type?</td>\n      <td>Bucket</td>\n      <td>f0/f0d50e0a.jpg</td>\n      <td>no</td>\n      <td>bucket</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>81CtH3N+0NL</td>\n      <td>What kind of closure does it have?</td>\n      <td>Lace-up</td>\n      <td>52/521668c5.jpg</td>\n      <td>sliding</td>\n      <td>lace-up</td>\n      <td>sliding</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8176aHTRP3L</td>\n      <td>What is the primary color?</td>\n      <td>Multi</td>\n      <td>43/438d87ff.jpg</td>\n      <td>blue</td>\n      <td>multi</td>\n      <td>blue</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71yC+5KLN-L</td>\n      <td>What material is the cover made of?</td>\n      <td>Hard</td>\n      <td>30/304914ac.jpg</td>\n      <td>metal</td>\n      <td>hard</td>\n      <td>metal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71pP-5SEtyL</td>\n      <td>What material is the case made of?</td>\n      <td>Silicone</td>\n      <td>40/40d177f8.jpg</td>\n      <td>metal</td>\n      <td>silicone</td>\n      <td>metal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## METRICS","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nacc = accuracy_score(test_df[\"Answer_clean\"], test_df[\"Pred_clean\"])\nprint(f\"Exact Match Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:15:58.028955Z","iopub.execute_input":"2025-05-18T08:15:58.029317Z","iopub.status.idle":"2025-05-18T08:15:58.061481Z","shell.execute_reply.started":"2025-05-18T08:15:58.029291Z","shell.execute_reply":"2025-05-18T08:15:58.060620Z"}},"outputs":[{"name":"stdout","text":"Exact Match Accuracy: 0.1725\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"!pip install bert-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:31:11.031514Z","iopub.execute_input":"2025-05-18T07:31:11.031817Z","iopub.status.idle":"2025-05-18T07:31:14.926773Z","shell.execute_reply.started":"2025-05-18T07:31:11.031798Z","shell.execute_reply":"2025-05-18T07:31:14.925961Z"}},"outputs":[{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.31.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.4.26)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert-score) (1.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert-score\nSuccessfully installed bert-score-0.3.13\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from bert_score import score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:16:06.594963Z","iopub.execute_input":"2025-05-18T08:16:06.595581Z","iopub.status.idle":"2025-05-18T08:16:06.599573Z","shell.execute_reply.started":"2025-05-18T08:16:06.595557Z","shell.execute_reply":"2025-05-18T08:16:06.598553Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"filtered_df = test_df[(test_df[\"Answer_clean\"] != \"\") & (test_df[\"Pred_clean\"] != \"\")]\n\nP, R, F1 = score(\n    filtered_df[\"Pred_clean\"].tolist(),\n    filtered_df[\"Answer_clean\"].tolist(),\n    lang=\"en\",\n    verbose=True\n)\n\nprint(f\"BERTScore - Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:16:11.281695Z","iopub.execute_input":"2025-05-18T08:16:11.282470Z","iopub.status.idle":"2025-05-18T08:16:17.300725Z","shell.execute_reply.started":"2025-05-18T08:16:11.282444Z","shell.execute_reply":"2025-05-18T08:16:17.299835Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f994cc01dee4d8d8f2b364d2fa601a3"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/249 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7656d2fa0e374f28b3725d3e82ecfd20"}},"metadata":{}},{"name":"stdout","text":"done in 4.92 seconds, 3236.22 sentences/sec\nBERTScore - Precision: 0.9517, Recall: 0.9251, F1: 0.9371\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"! pip install nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:16:27.739591Z","iopub.execute_input":"2025-05-18T08:16:27.740228Z","iopub.status.idle":"2025-05-18T08:16:31.127595Z","shell.execute_reply.started":"2025-05-18T08:16:27.740197Z","shell.execute_reply":"2025-05-18T08:16:31.126285Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import nltk\nnltk.download(\"wordnet\")\nnltk.download(\"omw-1.4\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:16:36.043580Z","iopub.execute_input":"2025-05-18T08:16:36.043921Z","iopub.status.idle":"2025-05-18T08:16:36.110627Z","shell.execute_reply.started":"2025-05-18T08:16:36.043887Z","shell.execute_reply":"2025-05-18T08:16:36.109853Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"from nltk.corpus import wordnet as wn\n\ndef wups_score(preds, refs, threshold=0.9):\n    def compute_wups(pred, ref):\n        pred_synsets = wn.synsets(pred)\n        ref_synsets = wn.synsets(ref)\n\n        if not pred_synsets or not ref_synsets:\n            return 0.0  # no synsets found → assume unrelated\n\n        max_score = max(wn.wup_similarity(p, r) or 0.0 for p in pred_synsets for r in ref_synsets)\n        return max_score\n\n    scores = []\n    for pred, ref in zip(preds, refs):\n        pred = pred.lower().strip()\n        ref = ref.lower().strip()\n\n        score = compute_wups(pred, ref)\n        score = score if score >= threshold else 0.0  # apply threshold\n        scores.append(score)\n\n    return sum(scores) / len(scores) if scores else 0.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:16:38.395895Z","iopub.execute_input":"2025-05-18T08:16:38.396545Z","iopub.status.idle":"2025-05-18T08:16:38.403172Z","shell.execute_reply.started":"2025-05-18T08:16:38.396520Z","shell.execute_reply":"2025-05-18T08:16:38.402193Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"refs = test_df[\"Answer_clean\"].tolist()\npreds = test_df[\"Pred_clean\"].tolist()\n\n# Calculate WUPS@0.0 (lenient) and WUPS@0.9 (strict)\nwups_00 = wups_score(preds, refs, threshold=0.0)\nwups_09 = wups_score(preds, refs, threshold=0.9)\n\nfinal_score = 0.5 * wups_00 + 0.5 * wups_09\n\n# Print results\nprint(f\"WUPS @0.0 (lenient): {wups_00:.4f}\")\nprint(f\"WUPS @0.9 (strict): {wups_09:.4f}\")\nprint(f\"Final Weighted WUPS Score: {final_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:16:41.573248Z","iopub.execute_input":"2025-05-18T08:16:41.573827Z","iopub.status.idle":"2025-05-18T08:18:44.710863Z","shell.execute_reply.started":"2025-05-18T08:16:41.573802Z","shell.execute_reply":"2025-05-18T08:18:44.710041Z"}},"outputs":[{"name":"stdout","text":"WUPS @0.0 (lenient): 0.4538\nWUPS @0.9 (strict): 0.2116\nFinal Weighted WUPS Score: 0.3327\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight & fast\n\npreds = test_df[\"predicted_answer\"].astype(str).tolist()\nrefs = test_df[\"answer\"].astype(str).tolist()\n\npred_embeds = model.encode(preds, convert_to_tensor=True)\nref_embeds = model.encode(refs, convert_to_tensor=True)\n\ncos_sim = util.cos_sim(pred_embeds, ref_embeds).diagonal()\n\nsbert_score = cos_sim.mean().item()\nprint(f\"SBERT Metric: {sbert_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:18:44.712119Z","iopub.execute_input":"2025-05-18T08:18:44.712485Z","iopub.status.idle":"2025-05-18T08:18:52.896588Z","shell.execute_reply.started":"2025-05-18T08:18:44.712459Z","shell.execute_reply":"2025-05-18T08:18:52.895753Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/498 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7b2aab93964b2481f6a8b451f586af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/498 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f766df327c4422692935aebf0943fae"}},"metadata":{}},{"name":"stdout","text":"SBERT Metric: 0.4584\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:18:52.897468Z","iopub.execute_input":"2025-05-18T08:18:52.897814Z","iopub.status.idle":"2025-05-18T08:18:52.903896Z","shell.execute_reply.started":"2025-05-18T08:18:52.897781Z","shell.execute_reply":"2025-05-18T08:18:52.903181Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"from nltk.translate.meteor_score import meteor_score\nfrom nltk.tokenize import word_tokenize\n\nmeteor_scores = [\n    meteor_score([word_tokenize(ref)], word_tokenize(pred))\n    for ref, pred in zip(test_df[\"answer\"].astype(str), test_df[\"predicted_answer\"].astype(str))\n]\n\navg_meteor = sum(meteor_scores) / len(meteor_scores)\nprint(f\"Average METEOR Score: {avg_meteor:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:18:52.905463Z","iopub.execute_input":"2025-05-18T08:18:52.905711Z","iopub.status.idle":"2025-05-18T08:18:55.315928Z","shell.execute_reply.started":"2025-05-18T08:18:52.905692Z","shell.execute_reply":"2025-05-18T08:18:55.315198Z"}},"outputs":[{"name":"stdout","text":"Average METEOR Score: 0.0994\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}